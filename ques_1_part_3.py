# -*- coding: utf-8 -*-
"""ques_1_part_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A7jPSEEWRuuWZF1zX1lrM3f0erbDq_cA
"""

#used to work with arrays
import numpy as np
#used to import dataset
import pandas as pd
# used for plotting the dataset
import matplotlib.pyplot as plt
#used for largest value 
import sys
#used for random values
import random
#for doing inverse  of matrices
from numpy.linalg import inv


url="https://drive.google.com/file/d/1X4yoAac3pLo5YluY2tsYRzCPud-9pIq1/view?usp=sharing"
url='https://drive.google.com/uc?id=' + url.split('/')[-2]


#storing the feature names of the dataset
name=[]
for i in range (1,51):
  name.append("X"+str(i))



#used the dataset url to import dataset
dataframe=pd.read_csv(url,names=name)
X=dataframe.T
X=np.array(X,float)
#X dataframe has 2 features and 1000 data frames. “n”  is the number of data points and number of features are stored in “number_of_features”
n=len(X[0])
number_of_features=len(X)



#initializing the cluster means 
def initialization(X,k):
  Z=[]
  for i in range(n):
    Z.append(0)
  mean=[]
  for i in range(len(X)):
    l=[]
    for j in range(k):
      l.append(0)
    mean.append(l)
  mean=np.array(mean,float)

  cluster_centers=np.random.randint(n, size=k)
  for j in range(len(cluster_centers)):
      mean[:,j]=X[:,cluster_centers[j]]


  #for each point ,we are taking the cluster center which is at minimum distance from it
  for i in range(n):
    x=X[:,i]
    min_dist=sys.maxsize;
    min_index=-1
    for j in range(k):
      mu=mean[:,j]
      x=np.array(x)
      mu=np.array(mu,float)
      dist=(np.dot((x-mu).T,(x-mu)))**0.5;
      if min_dist>dist:
        min_dist=dist
        min_index=j
    Z[i]=min_index
  return mean,Z





# error computation or objective value

def error(X,Z,mean):
  dist_sq=0
  for i in range(n):
    x=X[:,i]

    #computing distance of each component from its cluster's mean
    dist_sq+=np.dot((x-mean[:,Z[i]]).T,(x-mean[:,Z[i]]))
  return dist_sq



# mean computation steps

def mean_computation(X,Z,k):
  mean=[]
  for i in range(len(X)):
    l=[]
    for j in range(k):
      l.append(0)
    mean.append(l)
  mean=np.array(mean,float)

  #counting number of points in a cluster
  count=[]
  for i in range(k):
    count.append(0)

  #finding sum of all points in a cluster
  for i in range(n):
    count[Z[i]]+=1
    mean[:,Z[i]]=mean[:,Z[i]]+X[:,i]

  #finding mean of each cluster
  index=[]
  for i in range(k):
    if count[i]!=0:
      mean[:,i]=mean[:,i]/count[i]
    else:
      index.append(i)
  
  #deleting the mean point which has no other point in its cluster
  for i in index:
    np.delete(mean,index, axis=1)
  return mean




#checking if the points go to another cluster or not. if it goes then assigning  it to that cluster
def reassign(X,mean,k):
  Z=[]
  for i in range(n):
    Z.append(0)

  #for every datapoint we are computing distance to all  means and we are assigning the point to that cluster whose mean is closest to that point
  for i in range(n):
    x=X[:,i]
    min_dist=sys.maxsize;
    min_index=-1
    for index in range(k):
      mu=mean[:,index]
      x=np.array(x)
      mu=np.array(mu)
      dist=(np.dot((x-mu).T,(x-mu))**0.5);
      if min_dist>dist:
        min_dist=dist
        min_index=index
    Z[i]=min_index
  return Z




#function for kmeans
def kmeans(X,k):
  error_list=[]
  steps=[]
  step=1

  #initializing the datapoints and the means 
  mean,Z=initialization(X,k)


  #run a loop till no change  happens in the assignments of the clusters
  changes=True
  error_val=0
  while(changes):
    steps.append(step)

    #initializes the clusters and finds the mean of the datapoints 
    mean=mean_computation(X,Z,k)
    error_val=error(X,Z,mean)
    error_list.append(error_val)

    #reassign the datapoints into new clusters if it is possible  
    Z_new=reassign(X,mean,k)
    flag=False
    for i in range(len(Z_new)):
      if(Z[i]!=Z_new[i]):
        flag=True
        break
    if flag==True:
      changes=True
    else: changes=False
    Z=Z_new
    step=step+1
  return error_list,Z,mean,steps


k=4
error_list,Z,mean,steps=kmeans(X,k)
#diagram of error vs iteration
plt.figure(figsize=(8,8))
plt.plot(steps,error_list)
plt.title("error_list vs steps")
plt.xlabel("steps")
plt.ylabel("error_list")
plt.show()

X=X.T

count=np.zeros(4)
for i in range(400):
  count[Z[i]]=count[Z[i]] + 1



print(count)


mean1=np.zeros(50)
mean2=np.zeros(50)
mean3=np.zeros(50)
mean4=np.zeros(50)
count1=0
count2=0
count3=0
count4=0
for i in range(len(Z)):
  if Z[i] == 0:
    mean1=mean1 + X[i]
    count1=count1+1
  elif Z[i] == 1:
    mean2=mean2 + X[i]
    count2+=1
  elif Z[i] == 2:
    mean3=mean3 + X[i]
    count3+=1
  elif Z[i] == 3:
    mean4=mean4+X[i]
    count4+=1



mean1=mean1/count1
mean2=mean2/count2
mean3=mean3/count3
mean4=mean4/count4
mean = []
mean.append(mean1)
mean.append(mean2)
mean.append(mean3)
mean.append(mean4)


count=0
for i in range(400):
  a=X[i]-mean[Z[i]]
  b=np.matmul(a.T,a)
  count+=b


print(count)