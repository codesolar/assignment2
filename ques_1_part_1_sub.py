# -*- coding: utf-8 -*-
"""ques_1_part_1_sub.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HDZSnoYnvA-tGIjPH_11oUmDIGcD3xhO
"""

#used to work with arrays
import numpy as np
#used to import dataset
import pandas as pd
# used for plotting the dataset
import matplotlib.pyplot as plt
#used for largest value 
import sys
#used for random values
import random
#for doing inverse  of matrices
from numpy.linalg import pinv
import math

url="https://drive.google.com/file/d/1X4yoAac3pLo5YluY2tsYRzCPud-9pIq1/view?usp=sharing"
url='https://drive.google.com/uc?id=' + url.split('/')[-2]


#storing the feature names of the dataset
name=[]
for i in range (1,51):
  name.append("X"+str(i))



#used the dataset url to import dataset
dataframe=pd.read_csv(url,names=name)
X=np.array(dataframe,float)
#X dataframe has 2 features and 1000 data frames. “n”  is the number of data points and number of features are stored in “number_of_features”
n,d=X.shape




def lamda_sum(lamda ,k):
  sum=0
  for i in range(n):
    sum = sum + lamda[i][k]
  return sum

# mu and sigma are matrix
def compute_lamda(pi,x,P,k):
  a=pi[k] * pmf(x,P[k])
  b=0
  for i in range(4):
    b = b + pi[i] * pmf(x,P[i])
  return a/b

def get_pi(lamda,k):
  s= lamda_sum(lamda , k)
  return s/400


# x=X[i]--i th datapoint, mu = mu[k]
def pmf(x, P):
  product = 1
  for i in range(50):
    if x[i] == 1:
      product = product * P[i]
    else:
      product = product * (1-P[i])
  return product




def get_P(lamda,k):
  sum = 0
  for i in range(n):
    sum = sum + lamda[i][k]*X[i]
  a= lamda_sum(lamda , k)
  return sum / (a)




def loglikelyhood(PI_matrix,P):
  sum=0
  for i in range(400):
    part1=0
    for k in range(4):
      part1 = part1 + PI_matrix[k]*pmf(X[i],P[k])
    sum = sum + math.log(part1)
  return sum



def initialization(k):
  lamda=[]
  for i in range(400):
    temp = np.random.randint(10, size = k)
    s= np.sum(temp)
    temp= temp / s
    lamda.append(temp)

  P = []
  for k in range(4):
    P.append(get_P(lamda , k))
  
  pi=[]
  for k in range(4):
    pi.append(lamda_sum(lamda,k)/400)
  return lamda,P,pi




def EM(P,PI_matrix):
  lamda = []
  for i in range(400):
    temp= []
    for k in range(4):
      temp.append(compute_lamda(PI_matrix,X[i],P,k))
    lamda.append(temp)
  P = []
  for k in range(4):
    P.append(get_P(lamda , k))
  
  
  PI_matrix=[]
  for k in range(4):
    PI_matrix.append(lamda_sum(lamda,k)/400)
  return lamda,P,PI_matrix



log_array=[]
for i in range(50):
  lamda,P,PI_matrix=initialization(4)
  temp = []
  for j in range(10):
    lamda,P,PI_matrix=EM(P,PI_matrix)
    temp.append(loglikelyhood(PI_matrix,P))
  log_array.append(temp)



a=np.array(log_array,float)
print(a.shape)
# print(~np.isnan(a))
b=~np.isnan(a).any(axis = 1)
# a=a[~np.isnan(a)]
a=a[b]
print(a.shape)


plot_arr= []
for j in range(6):
  sum = 0
  for i in range(a.shape[0]):
    sum = sum + a[i][j]
  plot_arr.append(sum/a.shape[0])



steps=[i for i in range(1,7)]
plt.plot(steps,plot_arr)


z=np.argmax(lamda,axis=1)



count=np.zeros(4)
for i in range(400):
  count[z[i]]=count[z[i]] + 1



print(count)


mean1=np.zeros(50)
mean2=np.zeros(50)
mean3=np.zeros(50)
mean4=np.zeros(50)
count1=0
count2=0
count3=0
count4=0
for i in range(len(z)):
  if z[i] == 0:
    mean1=mean1 + X[i]
    count1=count1+1
  elif z[i] == 1:
    mean2=mean2 + X[i]
    count2+=1
  elif z[i] == 2:
    mean3=mean3 + X[i]
    count3+=1
  elif z[i] == 3:
    mean4=mean4+X[i]
    count4+=1



mean1=mean1/count1
mean2=mean2/count2
mean3=mean3/count3
mean4=mean4/count4
mean = []
mean.append(mean1)
mean.append(mean2)
mean.append(mean3)
mean.append(mean4)


count=0
for i in range(400):
  a=X[i]-mean[z[i]]
  b=np.matmul(a.T,a)
  count+=b


print(count)